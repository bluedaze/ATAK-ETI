<!--<!DOCTYPE html>-->
<!--<html>-->
<!--<head>-->
<!--<meta charset="utf-8">-->
<!--<link href="https://cdn.jsdelivr.net/npm/bootstrap@5.0.2/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha384-EVSTQN3/azprG1Anm3QDgpJLIm9Nao0Yz1ztcQTwFspd3yD65VohhpuuCOmLASjC" crossorigin="anonymous">-->
<!--<title>ETI Face Detection</title>-->
<!--<script src="{{url_for('static', filename='utils.js')}}"></script>-->
<!--<link rel= "stylesheet" type= "text/css" href= "{{ url_for('static',filename='style.css') }}">-->

<!--</head>-->
<!--<body>-->
<!--<div class="container-sm">-->
<!--    <div class ="row">-->
<!--        <h2>Face Detection Camera Example</h2>-->
<!--        <p>-->
<!--            Click <b>Start/Stop</b> button to start or stop the camera capture.<br>-->
<!--        </p>-->
<!--        <div class="card-group">-->
<!--            <div class="card h-100">-->
<!--                <canvas id="canvasOutput"></canvas>-->
<!--                <div class="card-body">-->
<!--                    <div class="control">-->
<!--                        <div class="d-grid gap-2">-->
<!--                            <button id="startAndStop" class="btn btn-primary" type="button">Start</button>-->
<!--                        </div>-->
<!--                    </div>-->
<!--                </div>-->
<!--            </div>-->
<!--        </div>-->
<!--    </div>-->
<!--</div>-->
<!--        <p class="err" id="errorMessage"></p>-->
<!--        <video id="videoInput" hidden></video>-->



<!--<script src="https://webrtc.github.io/adapter/adapter-5.0.4.js" type="text/javascript"></script>-->

<!--<script>-->
<!--function detectFaces(){-->
<!--let video = document.getElementById('videoInput');-->
<!--let src = new cv.Mat(video.height, video.width, cv.CV_8UC4);-->
<!--let dst = new cv.Mat(video.height, video.width, cv.CV_8UC4);-->
<!--let gray = new cv.Mat();-->
<!--let cap = new cv.VideoCapture(video);-->
<!--let faces = new cv.RectVector();-->
<!--let classifier = new cv.CascadeClassifier();-->

<!--// load pre-trained classifiers-->
<!--classifier.load('haarcascade_frontalface_default.xml');-->

<!--const FPS = 30;-->
<!--function processVideo() {-->
<!--    try {-->
<!--        if (!streaming) {-->
<!--            // clean and stop.-->
<!--            src.delete();-->
<!--            dst.delete();-->
<!--            gray.delete();-->
<!--            faces.delete();-->
<!--            classifier.delete();-->
<!--            return;-->
<!--        }-->
<!--        let begin = Date.now();-->
<!--        // start processing.-->
<!--        cap.read(src);-->
<!--        src.copyTo(dst);-->
<!--        cv.cvtColor(dst, gray, cv.COLOR_RGBA2GRAY, 0);-->
<!--        // detect faces.-->
<!--        let detection = classifier.detectMultiScale(gray, faces, 1.1, 3, 0);-->
<!--        // draw faces.-->
<!--        // console.log(faces.size()) <-&#45;&#45; Use this to detect faces-->
<!--        if (faces.size() > 0){-->
<!--            console.log("Creating type");-->
<!--            var type = "image/png";-->
<!--            console.log("creating dataURL");-->
<!--            var data = document.getElementById("canvasOutput").toDataURL(type);-->
<!--            console.log("Encoding to base64");-->
<!--            data = data.replace('data:' + type + ';base64,', '');-->
<!--            console.log("emitting to socket")-->
<!--            socket.emit('image', data);-->
<!--            console.log("Exiting if statement")-->
<!--        }-->
<!--        for (let i = 0; i < faces.size(); ++i) {-->
<!--            let face = faces.get(i);-->
<!--            let point1 = new cv.Point(face.x, face.y);-->
<!--            let point2 = new cv.Point(face.x + face.width, face.y + face.height);-->
<!--            cv.rectangle(dst, point1, point2, [255, 0, 0, 255]);-->
<!--        }-->
<!--        cv.imshow('canvasOutput', dst);-->
<!--        // schedule the next one.-->
<!--        let delay = 1000/FPS - (Date.now() - begin);-->
<!--        setTimeout(processVideo, delay);-->
<!--    } catch (err) {-->
<!--        utils.printError(err);-->
<!--    }-->
<!--};-->

<!--// schedule the first one.-->
<!--setTimeout(processVideo, 0);-->
<!--}-->

<!--let utils = new Utils('errorMessage');-->

<!--let streaming = false;-->
<!--let videoInput = document.getElementById('videoInput');-->
<!--let startAndStop = document.getElementById('startAndStop');-->
<!--let canvasOutput = document.getElementById('canvasOutput');-->
<!--let canvasContext = canvasOutput.getContext('2d');-->




<!--startAndStop.addEventListener('click', () => {-->
<!--    if (!streaming) {-->
<!--        utils.clearError();-->
<!--        utils.startCamera('qvga', onVideoStarted, 'videoInput');-->
<!--    } else {-->
<!--        utils.stopCamera();-->
<!--        onVideoStopped();-->
<!--    }-->
<!--});-->

<!--function onVideoStarted() {-->
<!--    streaming = true;-->
<!--    startAndStop.innerText = 'Stop';-->
<!--    videoInput.width = videoInput.videoWidth;-->
<!--    videoInput.height = videoInput.videoHeight;-->
<!--    detectFaces()-->
<!--}-->

<!--function onVideoStopped() {-->
<!--    streaming = false;-->
<!--    canvasContext.clearRect(0, 0, canvasOutput.width, canvasOutput.height);-->
<!--    startAndStop.innerText = 'Start';-->
<!--}-->

<!--utils.loadOpenCv(() => {-->
<!--    console.log("openCV loaded")-->
<!--    let faceCascadeFile = "/static/haarcascade_frontalface_default.xml"-->
<!--    utils.createFileFromUrl(faceCascadeFile, faceCascadeFile, () => {-->
<!--    alert(faceCascadeFile);-->
<!--    classifier.load(faceCascadeFile);-->
<!--    });-->
<!--});-->



<!--</script>-->
<!--<script src="https://cdn.jsdelivr.net/npm/bootstrap@5.0.2/dist/js/bootstrap.bundle.min.js" integrity="sha384-MrcW6ZMFYlzcLA8Nl+NtUVF0sA7MsXsP1UyJoMp4YLEuNSfAP+JcXn/tWtIaxVXM" crossorigin="anonymous"></script>-->
<!--</body>-->
<!--</html>-->

<!DOCTYPE html>
<html>
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1">
<title>ETI Check In</title>
<script type='text/javascript' src="{{url_for('static', filename='opencv.js')}}"></script>
<script type='text/javascript' src="{{url_for('static', filename='utils.js')}}"></script>
<script type='text/javascript' src="https://code.jquery.com/jquery-1.12.4.min.js"></script>
<link rel= "stylesheet" type= "text/css" href= "{{ url_for('static',filename='style.css') }}">
<script type='text/javascript'>

function init()
{
    let video = document.getElementById('videoInput');
    let container = document.getElementById('container');
    let canvasOutput = document.getElementById("canvasOutput");
    if (navigator.mediaDevices.getUserMedia){
        navigator.mediaDevices.getUserMedia({ video: true })
        .then(function (stream) {
                video.srcObject = stream;
            video.addEventListener('canplay', () => {
                var screenWidth = $(document).width();
                var screenHeight = $(document).height();
                var headerHeight = $('#header').height();
                var messageboxHeight = $('#messagebox').height();
                var ratio = 1.0;
                video.width = video.videoWidth;
                video.height = video.videoHeight;
                if (video.width > screenWidth || video.height + headerHeight + messageboxHeight > screenHeight){
                    ratio = Math.min(screenWidth / (video.width * 1.0), screenHeight / ((video.height + headerHeight + messageboxHeight) * 1.0));
                }
                container.style.width = Math.round(video.width * ratio) + 'px';
                container.style.height = Math.round(video.height * ratio) + 'px';
                canvasOutput.width = Math.round(video.width * ratio);
                canvasOutput.height = Math.round(video.height * ratio);
                load_cascade();
            });
        }).catch(function (err0r) {
            console.log("Something went wrong!");
            streaming = false;
        });
    }
}

function load_cascade()
{
    let faceCascadeFile = 'haarcascade_frontalface_default.xml'
    let faceCascadeURL = 'static/haarcascade_frontalface_default.xml'
    let utils = new Utils('errorMessage');
    utils.createFileFromUrl(faceCascadeFile, faceCascadeURL, () => {
        main()
    });
}


function main()
{
    let video = document.getElementById("videoInput");
    let canvasOutput = document.getElementById("canvasOutput");
    let canvasContext = canvasOutput.getContext('2d');
    let src = new cv.Mat(video.height, video.width, cv.CV_8UC4);
    let dst = new cv.Mat(video.height, video.width, cv.CV_8UC4);
    let msize = new cv.Size(video.width / 4, video.height / 4);
    let dsize = new cv.Size(canvasOutput.width, canvasOutput.height);
    let cap = new cv.VideoCapture(video);
    let faces = new cv.RectVector();
    let classifier = new cv.CascadeClassifier();
    class Tracker{
        constructor(){
            this.arr = new Array();
        }
        register = function(x, y, width, height) {
        var x_center = (x + width) / 2;
        var y_center = (y + height) / 2;
        var now = Date.now()
        this.arr = this.arr.filter(ent => now - ent.time < 300);
            for (const prop in this.arr){
            var prop_x_center = (this.arr[prop].x + this.arr[prop].width) / 2;
            var prop_y_center = (this.arr[prop].y + this.arr[prop].height) / 2;
                if (Math.abs(x_center - prop_x_center) < 10 && Math.abs(y_center - prop_y_center) < 10){
                this.arr[prop].x = x;
                this.arr[prop].y = y;
                this.arr[prop].width = width;
                this.arr[prop].height = height;
                this.arr[prop].time = now;
                return false;
            }
        }
        var ent = {x: x, y: y, width: width, height: height, time: now}
        this.arr.push(ent)
        return true;
        }
    };
    var tracker = new Tracker();
    var streaming = true;

    classifier.load('haarcascade_frontalface_default.xml');

    const FPS = 30;
    function processVideo() {
        try {
            if (!streaming) {
                // clean and stop.
                src.delete();
                dst.delete();
                faces.delete();
                classifier.delete();
                return;
            }
            let begin = Date.now();
            // start processing.
            cap.read(src);
            cv.flip(src, src, 1);
            src.copyTo(dst);
            // detect faces.
            classifier.detectMultiScale(dst, faces, 1.1, 5, 0, msize);
            // draw faces.
            for (let i = 0; i < faces.size(); ++i) {
                let face = faces.get(i);
                let point1 = new cv.Point(face.x, face.y);
                let point2 = new cv.Point(face.x + face.width, face.y + face.height);
                cv.rectangle(dst, point1, point2, [255, 0, 0, 255], 8);
                let cropped = new cv.Mat();
                let margin_x = 0;
                let margin_y = 0;
                if (face.width > face.height)
                {
                    margin_y = (face.width - face.height) / 2;
                }
                else
                {
                    margin_x = (face.height - face.width) / 2;
                }
                Math.max(face.width, face.height)
                Math.min(face.width, face.height)
                let rect = new cv.Rect(Math.max(face.x-margin_x, 0), Math.max(face.y-margin_y, 0), Math.min(face.width+margin_x, src.cols), Math.min(face.height+margin_y, src.rows));
                cropped = src.roi(rect);
                let tempCanvas = document.createElement("canvas");
                cv.imshow(tempCanvas,cropped);
                if (tracker.register(face.x, face.y, face.width, face.height)){
                    let b64encoded = tempCanvas.toDataURL("image/jpeg", 0.6);
                    b64encoded = b64encoded.replace('data:image/jpeg;base64,', '');
                    $.ajax({
                        type: "POST",
                        url: "/verify",
                        dataType: "json",
                        data: {'image':b64encoded},
                        success: function(data){
                           if (data.status == "attend"){
                               var newHead = "<div class='message attend'>";
                               var newTail = "</div>";
                               var newContent = '[' + data.student_id + '/' + data.student_name + ']' + "출석되었습니다.";
                               $('#messagebox').prepend(newHead + newContent + newTail).stop().animate({ scrollTop: 0 }, 1000);
                           }
                           else if (data.status == "already"){
                               var newHead = "<div class='message already'>";
                               var newTail = "</div>";
                               var newContent = '[' + data.student_id + '/' + data.student_name + ']' + "이미 출석되었습니다.";
                               $('#messagebox').prepend(newHead + newContent + newTail).stop().animate({ scrollTop: 0 }, 1000);
                           }
                           else if (data.status == "fail"){
                               var newHead = "<div class='message fail'>";
                               var newTail = "</div>";
                               var newContent = "인식 실패";
                               $('#messagebox').prepend(newHead + newContent + newTail).stop().animate({ scrollTop: 0 }, 1000);
                           }
                        }
                    });
                }
            }
            // to do resize preview
            cv.resize(dst, dst, dsize, 0, 0, cv.INTER_AREA);
            cv.imshow('canvasOutput', dst);
            // schedule the next one.
            let delay = 1000/FPS - (Date.now() - begin);
            setTimeout(processVideo, delay);
        } catch (err) {
            console.log(err);
        }
    }
    setTimeout(processVideo, 0);
}

</script>
</head>

<body onload="cv['onRuntimeInitialized']=()=>{ init(); };">
         <div id="header">
        <header class="w3-container w3-center w3-padding-32">
            <b><h2>Face Detection Camera Example</h2></b>
            <p>Look directly into the camera and take off any classes, or headgear.<br></p>
        </header>
         </div>
            <div id="container">
            <video autoplay="true" id="videoInput" style="display: none; object-fit: cover;"></video>
            <canvas id="canvasOutput"></canvas>
            </div>
        <p class="err" id="errorMessage"></p>
</body>
</html>
